{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcMhSqPLday3pg0Kg860gi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kuhlman-Lab/ThermoMPNN-D/blob/main/ThermoMPNN-D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center>**This is a Colab implementation of ThermoMPNN-D**</center>\n",
        "\n",
        "---\n",
        "\n",
        "ThermoMPNN-D is an updated version of ThermoMPNN for predicting double point mutations.\n",
        "\n",
        "It was trained on an augmented version of the Megascale double mutant dataset. It is state-of-the-art at predicting stabilizing double mutations.\n",
        "\n",
        "\n",
        "### **COLAB TIPS:**\n",
        "- The cells of this notebook are meant to be executed *in order*, so users should start from the top and work their way down.\n",
        "- Executable cells can be run by clicking the PLAY button (>) that appears when you hover over each cell, or by using **Shift+Enter**.\n",
        "- Make sure GPU is enabled by checking `Runtime` -> `Change Runtime Type`\n",
        "  - Make sure that `Runtime type` is set to `Python 3`\n",
        "  - Make sure that `Hardware accelerator` is set to `GPU`\n",
        "  - Click `Save` to confirm\n",
        "\n",
        "- If the notebook freezes up or otherwise crashes, go to `Runtime` -> `Restart Runtime` and try again.\n"
      ],
      "metadata": {
        "id": "hPU-s3e_ex-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "#@title # 1. Set up **ThermoMPNN environment**\n",
        "#@markdown Import ThermoMPNN and its dependencies to this session. This may take a minute or two.\n",
        "\n",
        "#@markdown You only need to do this once *per session*. To re-run ThermoMPNN on a new protein, you may start on Step 3.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "# cleaning out any remaining data\n",
        "!cd /content\n",
        "!rm -rf /content/ThermoMPNN-D\n",
        "!rm -rf /content/sample_data\n",
        "!rm /content/*.pdb\n",
        "!rm /content/*.csv\n",
        "\n",
        "# import ThermoMPNN-D github repo\n",
        "import os\n",
        "if not os.path.exists(\"/content/ThermoMPNN-D\"):\n",
        "  !git clone https://github.com/Kuhlman-Lab/ThermoMPNN-D.git\n",
        "  %cd /content/ThermoMPNN-D\n",
        "\n",
        "# downloading various dependencies - add more if needed later\n",
        "! pip install omegaconf wandb pytorch-lightning biopython nglview\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zqSoIY9hfaae"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # **2. Set up ThermoMPNN imports and functions**\n",
        "\n",
        "# Setting up imports and functions for use later in the protocol\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "import sys\n",
        "from urllib import request\n",
        "from urllib.error import HTTPError\n",
        "from google.colab._message import MessageError\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from Bio.PDB import PDBParser\n",
        "from omegaconf import OmegaConf\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "tMPNN_path = '/content/ThermoMPNN-D'\n",
        "if tMPNN_path not in sys.path:\n",
        "  sys.path.append(tMPNN_path)\n",
        "\n",
        "from thermompnn.datasets.dataset_utils import Mutation\n",
        "from thermompnn.datasets.v2_datasets import tied_featurize_mut\n",
        "\n",
        "from thermompnn.train_thermompnn import parse_cfg\n",
        "from thermompnn.trainer.v2_trainer import TransferModelPLv2\n",
        "\n",
        "def download_pdb(pdbcode, datadir, downloadurl=\"https://files.rcsb.org/download/\"):\n",
        "    \"\"\"\n",
        "    Downloads a PDB file from the Internet and saves it in a data directory.\n",
        "    :param pdbcode: The standard PDB ID e.g. '3ICB' or '3icb'\n",
        "    :param datadir: The directory where the downloaded file will be saved\n",
        "    :param downloadurl: The base PDB download URL, cf.\n",
        "        `https://www.rcsb.org/pages/download/http#structures` for details\n",
        "    :return: the full path to the downloaded PDB file or None if something went wrong\n",
        "    \"\"\"\n",
        "\n",
        "    pdbfn = pdbcode + \".pdb\"\n",
        "    url = downloadurl + pdbfn\n",
        "    outfnm = os.path.join(datadir, pdbfn)\n",
        "    try:\n",
        "        request.urlretrieve(url, outfnm)\n",
        "        return outfnm\n",
        "    except Exception as err:\n",
        "        print(str(err), file=sys.stderr)\n",
        "        return None\n",
        "\n",
        "def alt_parse_PDB_biounits(x, atoms=['N', 'CA', 'C'], chain=None):\n",
        "    '''\n",
        "  input:  x = PDB filename\n",
        "          atoms = atoms to extract (optional)\n",
        "  output: (length, atoms, coords=(x,y,z)), sequence\n",
        "  '''\n",
        "\n",
        "    alpha_1 = list(\"ARNDCQEGHILKMFPSTWYV-\")\n",
        "    states = len(alpha_1)\n",
        "    alpha_3 = ['ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'ILE',\n",
        "               'LEU', 'LYS', 'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL', 'GAP']\n",
        "\n",
        "    aa_1_N = {a: n for n, a in enumerate(alpha_1)}\n",
        "    aa_3_N = {a: n for n, a in enumerate(alpha_3)}\n",
        "    aa_N_1 = {n: a for n, a in enumerate(alpha_1)}\n",
        "    aa_1_3 = {a: b for a, b in zip(alpha_1, alpha_3)}\n",
        "    aa_3_1 = {b: a for a, b in zip(alpha_1, alpha_3)}\n",
        "\n",
        "    def AA_to_N(x):\n",
        "        # [\"ARND\"] -> [[0,1,2,3]]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 0: x = x[None]\n",
        "        return [[aa_1_N.get(a, states - 1) for a in y] for y in x]\n",
        "\n",
        "    def N_to_AA(x):\n",
        "        # [[0,1,2,3]] -> [\"ARND\"]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 1: x = x[None]\n",
        "        return [\"\".join([aa_N_1.get(a, \"-\") for a in y]) for y in x]\n",
        "\n",
        "    xyz, seq, min_resn, max_resn = {}, {}, 1e6, -1e6\n",
        "    resn_list = []\n",
        "    for line in open(x, \"rb\"):\n",
        "        line = line.decode(\"utf-8\", \"ignore\").rstrip()\n",
        "\n",
        "        # handling MSE and SEC residues\n",
        "        if line[:6] == \"HETATM\" and line[17:17 + 3] == \"MSE\":\n",
        "            line = line.replace(\"HETATM\", \"ATOM  \")\n",
        "            line = line.replace(\"MSE\", \"MET\")\n",
        "        elif line[17:17 + 3] == \"MSE\":\n",
        "            line = line.replace(\"MSE\", \"MET\")\n",
        "        elif line[17:17 + 3] == \"SEC\":\n",
        "            line = line.replace(\"SEC\", \"CYS\")\n",
        "\n",
        "        if line[:4] == \"ATOM\":\n",
        "            ch = line[21:22]\n",
        "            if ch == chain or chain is None:\n",
        "                atom = line[12:12 + 4].strip()\n",
        "                resi = line[17:17 + 3]\n",
        "                resn = line[22:22 + 5].strip()\n",
        "\n",
        "                # RAW resn is defined HERE\n",
        "                if resn not in resn_list:\n",
        "                  resn_list.append(resn) # NEED to keep ins code here\n",
        "                x, y, z = [float(line[i:(i + 8)]) for i in [30, 38, 46]]\n",
        "                if resn[-1].isalpha():\n",
        "                    resa, resn = resn[-1], int(resn[:-1]) - 1\n",
        "                else:\n",
        "                    resa, resn = \"\", int(resn) - 1\n",
        "                if resn < min_resn:\n",
        "                    min_resn = resn\n",
        "                if resn > max_resn:\n",
        "                    max_resn = resn\n",
        "                if resn not in xyz:\n",
        "                    xyz[resn] = {}\n",
        "                if resa not in xyz[resn]:\n",
        "                    xyz[resn][resa] = {}\n",
        "                if resn not in seq:\n",
        "                    seq[resn] = {}\n",
        "                if resa not in seq[resn]:\n",
        "                    seq[resn][resa] = resi\n",
        "\n",
        "                if atom not in xyz[resn][resa]:\n",
        "                    xyz[resn][resa][atom] = np.array([x, y, z])\n",
        "                # print(resn_list)\n",
        "\n",
        "    # convert to numpy arrays, fill in missing values\n",
        "    seq_, xyz_ = [], []\n",
        "    # print(seq)\n",
        "    try:\n",
        "        for resn in range(min_resn, max_resn + 1):\n",
        "            if resn in seq:\n",
        "              # CLEANED resn is defined HERE\n",
        "                # resn_list.append(str(resn + 1))\n",
        "                # print(resn)\n",
        "                for k in sorted(seq[resn]): seq_.append(aa_3_N.get(seq[resn][k], 20))\n",
        "            else:\n",
        "                seq_.append(20)\n",
        "\n",
        "            if resn in xyz:\n",
        "                for k in sorted(xyz[resn]):\n",
        "                    for atom in atoms:\n",
        "                        if atom in xyz[resn][k]:\n",
        "                            xyz_.append(xyz[resn][k][atom])\n",
        "                        else:\n",
        "                            xyz_.append(np.full(3, np.nan))\n",
        "            else:\n",
        "                for atom in atoms: xyz_.append(np.full(3, np.nan))\n",
        "        return np.array(xyz_).reshape(-1, len(atoms), 3), N_to_AA(np.array(seq_)), list(dict.fromkeys(resn_list))\n",
        "    except TypeError:\n",
        "        return 'no_chain', 'no_chain', 'no_chain'\n",
        "\n",
        "def alt_parse_PDB(path_to_pdb, input_chain_list=None, ca_only=False, side_chains=False, mut_chain=None):\n",
        "    c = 0\n",
        "    pdb_dict_list = []\n",
        "    init_alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
        "                     'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n',\n",
        "                     'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "    extra_alphabet = [str(item) for item in list(np.arange(300))]\n",
        "    chain_alphabet = init_alphabet + extra_alphabet\n",
        "\n",
        "    if input_chain_list:\n",
        "        chain_alphabet = input_chain_list\n",
        "\n",
        "    biounit_names = [path_to_pdb]\n",
        "    for biounit in biounit_names:\n",
        "        my_dict = {}\n",
        "        s = 0\n",
        "        concat_seq = ''\n",
        "        concat_N = []\n",
        "        concat_CA = []\n",
        "        concat_C = []\n",
        "        concat_O = []\n",
        "        concat_mask = []\n",
        "        coords_dict = {}\n",
        "        for letter in chain_alphabet:\n",
        "            if ca_only:\n",
        "                sidechain_atoms = ['CA']\n",
        "            elif side_chains:\n",
        "                sidechain_atoms = [\"N\", \"CA\", \"C\", \"O\", \"CB\",\n",
        "                                   \"CG\", \"CG1\", \"OG1\", \"OG2\", \"CG2\", \"OG\", \"SG\",\n",
        "                                   \"CD\", \"SD\", \"CD1\", \"ND1\", \"CD2\", \"OD1\", \"OD2\", \"ND2\",\n",
        "                                   \"CE\", \"CE1\", \"NE1\", \"OE1\", \"NE2\", \"OE2\", \"NE\", \"CE2\", \"CE3\",\n",
        "                                   \"NZ\", \"CZ\", \"CZ2\", \"CZ3\", \"CH2\", \"OH\", \"NH1\", \"NH2\"]\n",
        "            else:\n",
        "                sidechain_atoms = ['N', 'CA', 'C', 'O']\n",
        "            xyz, seq, resn_list = alt_parse_PDB_biounits(biounit, atoms=sidechain_atoms, chain=letter)\n",
        "            if mut_chain is not None:\n",
        "              if resn_list != 'no_chain' and letter in mut_chain:\n",
        "                  my_dict['resn_list'] = list(resn_list)\n",
        "            if type(xyz) != str:\n",
        "                concat_seq += seq[0]\n",
        "                my_dict['seq_chain_' + letter] = seq[0]\n",
        "                coords_dict_chain = {}\n",
        "                if ca_only:\n",
        "                    coords_dict_chain['CA_chain_' + letter] = xyz.tolist()\n",
        "                elif side_chains:\n",
        "                    coords_dict_chain['SG_chain_' + letter] = xyz[:, 11].tolist()\n",
        "                else:\n",
        "                    coords_dict_chain['N_chain_' + letter] = xyz[:, 0, :].tolist()\n",
        "                    coords_dict_chain['CA_chain_' + letter] = xyz[:, 1, :].tolist()\n",
        "                    coords_dict_chain['C_chain_' + letter] = xyz[:, 2, :].tolist()\n",
        "                    coords_dict_chain['O_chain_' + letter] = xyz[:, 3, :].tolist()\n",
        "                my_dict['coords_chain_' + letter] = coords_dict_chain\n",
        "                s += 1\n",
        "\n",
        "        fi = biounit.rfind(\"/\")\n",
        "        if mut_chain is None:\n",
        "          my_dict['resn_list'] = list(resn_list)\n",
        "        my_dict['name'] = biounit[(fi + 1):-4]\n",
        "        my_dict['num_of_chains'] = s\n",
        "        my_dict['seq'] = concat_seq\n",
        "        # my_dict['resn_list'] = list(resn_list)\n",
        "        if s <= len(chain_alphabet):\n",
        "            pdb_dict_list.append(my_dict)\n",
        "            c += 1\n",
        "    return pdb_dict_list\n",
        "\n",
        "def get_chains_from_pdb(pdb_file):\n",
        "  parser = PDBParser(QUIET=True)\n",
        "  structure = parser.get_structure('', pdb_file)\n",
        "  return [c.id for c in structure.get_chains()]\n",
        "\n",
        "def get_chains(pdb_file, chain_list):\n",
        "  # collect list of chains in PDB to match with input\n",
        "  pdb_chains = get_chains_from_pdb(pdb_file)\n",
        "  if len(chain_list) < 1: # fill in all chains if left blank\n",
        "    chain_list = pdb_chains\n",
        "\n",
        "  for ch in chain_list:\n",
        "    assert ch in pdb_chains, f\"Chain {ch} not found in PDB file with chains {pdb_chains}\"\n",
        "\n",
        "  return chain_list"
      ],
      "metadata": {
        "id": "3Lgz5km3gFyv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "#@title # **3. Upload or Fetch Input Data**\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "import sys\n",
        "from urllib import request\n",
        "from urllib.error import HTTPError\n",
        "from google.colab._message import MessageError\n",
        "\n",
        "#@markdown ## You may either specify a PDB code to fetch or upload a custom PDB file.<br><br>\n",
        "\n",
        "# -------- Collecting Settings for ThermoMPNN run --------- #\n",
        "\n",
        "!rm /content/*.pdb &> /dev/null\n",
        "\n",
        "#@markdown PDB code (example: 1PGA):\n",
        "PDB = \"1PGA\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Upload Custom PDB?\n",
        "Custom = False #@param {type: \"boolean\"}\n",
        "#@markdown NOTE: If enabled, a `Choose files` button will appear at the bottom of this cell once this cell is run.\n",
        "\n",
        "\n",
        "# try to upload the PDB file to Colab servers\n",
        "if Custom:\n",
        "  try:\n",
        "    uploaded_pdb = files.upload()\n",
        "    for fn in uploaded_pdb.keys():\n",
        "      PDB = os.path.basename(fn)\n",
        "      if not PDB.endswith('.pdb'):\n",
        "        raise ValueError(f\"Uploaded file {PDB} does not end in '.pdb'. Please check and rename file as needed.\")\n",
        "      os.rename(fn, os.path.join(\"/content/\", PDB))\n",
        "      pdb_file = os.path.join(\"/content/\", PDB)\n",
        "  except (MessageError, FileNotFoundError):\n",
        "    print('\\n', '*' * 100, '\\n')\n",
        "    print('Sorry, your input file failed to upload. Please try the backup upload procedure (next cell).')\n",
        "\n",
        "else:\n",
        "  try:\n",
        "    fn = download_pdb(PDB, \"/content/\")\n",
        "    if fn is None:\n",
        "      raise ValueError(\"Failed to fetch PDB from RSCB. Please double-check PDB code and try again.\")\n",
        "    else:\n",
        "      pdb_file = fn\n",
        "  except HTTPError:\n",
        "    raise HTTPError(f\"No protein with code {PDB} exists in RSCB PDB. Please double-check PDB code and try again.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WPhbnMAHf1qL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # **3. Backup Data Upload (ONLY needed if initial upload failed)**\n",
        "\n",
        "#@markdown ## Colab automatic file uploads are not very reliable. If your file failed to upload automatically, you can do so manually by following these steps.<br><br>\n",
        "\n",
        "#@markdown #### 1. Click the \"Files\" icon on the left toolbar. This will open the Colab server file folder.\n",
        "\n",
        "#@markdown #### 2. The only thing in this folder should be \"ThermoMPNN\" directory. If any other files are in here, delete them.\n",
        "\n",
        "#@markdown #### 3. Click the \"Upload to session storage\" button under the \"Files\" header. Choose your file for upload.\n",
        "\n",
        "#@markdown #### 4. Run this cell. ThermoMPNN will find your file in session storage and use it.\n",
        "\n",
        "PDB = \"\"\n",
        "\n",
        "files = sorted(os.listdir('/content/'))\n",
        "files = [f for f in files if f.endswith('.pdb')]\n",
        "\n",
        "if len(files) < 1:\n",
        "  raise ValueError('No PDB file found. Please upload your file before running this cell. Make sure it has a .pdb suffix.')\n",
        "elif len(files) > 1:\n",
        "  raise ValueError('Too many PDB files found. Please clear out any other PDBs before running this cell.')\n",
        "else:\n",
        "  pdb_file = os.path.join(\"/content/\", files[0])\n",
        "  PDB = files[0].removesuffix('.pdb')\n",
        "  print('Successfully uploaded PDB file %s' % (files[0]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RjdyW_tmglI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **4. Run Model**\n",
        "\n",
        "#@markdown Stability model to use:\n",
        "Model = \"Epistatic\" #@param [\"Epistatic\", \"Additive\", \"Single\"]\n",
        "\n",
        "#@markdown Chain(s) of Interest (example: A,B,C):\n",
        "Chains = \"A\" #@param {type:\"string\"}\n",
        "#@markdown If left empty, all chains will be used.\n",
        "\n",
        "#@markdown ---------------\n",
        "#@markdown Include Cysteines?\n",
        "Include = False #@param {type: \"boolean\"}\n",
        "#@markdown NOTE: Due to assay artifacts surrounding disulfide formation, model predictions for surface cysteine mutations may be overly favorable.\n",
        "\n",
        "#@markdown Explicitly penalize disulfide breakage? Recommended.\n",
        "Penalize = True #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown --------------\n",
        "\n",
        "BatchSize = 256 #@param {type: \"integer\"}\n",
        "#@markdown Recommended: 256 (single/additive) or 2048 (epistatic). Should be lowered if you hit a memory error.\n",
        "\n",
        "Threshold = -0.5 #@param {type: \"number\"}\n",
        "#@markdown Ignored for single mutant model. Only mutations BELOW (more stable than) this threshold are kept. This is useful for speed and memory, since double mutation data grows exponentially.\n",
        "\n",
        "Distance = 10.0 #@param {type: \"number\"}\n",
        "#@markdown Ignored for single mutant model. Only mutation pairs BELOW (within) this distance (in Angstrom) are kept. Useful for speed and memory savings.\n",
        "\n",
        "# ---------- END OPTIONS -------------- #\n",
        "\n",
        "# use input_chain_list to grab correct protein chain\n",
        "chain_list = Chains.strip().split(',')\n",
        "\n",
        "# validate chain inputs\n",
        "chain_list = get_chains(pdb_file, chain_list)\n",
        "print(f'Using ThermoMPNN-I to predict stability across chain(s): {chain_list}')\n",
        "\n",
        "# remove cys from alphabet if needed\n",
        "alphabet = 'ACDEFGHIKLMNPQRSTVWY' if Include else 'ADEFGHIKLMNPQRSTVWY'\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-bxta5Lvgheo",
        "outputId": "a416adf0-7240-44fa-8eab-ef4981e32f62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using ThermoMPNN-I to predict stability across chain(s): ['A']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load config and model\n",
        "\n",
        "# load mutation dataset\n",
        "\n",
        "# run inference\n",
        "\n",
        "# collate output data"
      ],
      "metadata": {
        "id": "qisnoLI-iddh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}