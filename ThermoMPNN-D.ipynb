{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPolOCCVN1jIeQ44h440oDJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kuhlman-Lab/ThermoMPNN-D/blob/main/ThermoMPNN-D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center>**This is a Colab implementation of ThermoMPNN-D**</center>\n",
        "\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?export=view&id=1qXMpih7MLeZfRDZF9-iYSlL6SXEY3FdS'></center>\n",
        "\n",
        "---\n",
        "\n",
        "ThermoMPNN-D is an updated version of ThermoMPNN for predicting double point mutations.\n",
        "\n",
        "It was trained on an augmented version of the Megascale double mutant dataset. It is state-of-the-art at predicting stabilizing double mutations.\n",
        "\n",
        "\n",
        "### **COLAB TIPS:**\n",
        "- The cells of this notebook are meant to be executed *in order*, so users should start from the top and work their way down.\n",
        "- Executable cells can be run by clicking the PLAY button (>) that appears when you hover over each cell, or by using **Shift+Enter**.\n",
        "- Make sure GPU is enabled by checking `Runtime` -> `Change Runtime Type`\n",
        "  - Make sure that `Runtime type` is set to `Python 3`\n",
        "  - Make sure that `Hardware accelerator` is set to `GPU`\n",
        "  - Click `Save` to confirm\n",
        "\n",
        "- If the notebook freezes up or otherwise crashes, go to `Runtime` -> `Restart Runtime` and try again.\n"
      ],
      "metadata": {
        "id": "hPU-s3e_ex-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "\n",
        "#@title # 1. Set up **ThermoMPNN environment**\n",
        "#@markdown Import ThermoMPNN and its dependencies to this session. This may take a minute or two.\n",
        "\n",
        "#@markdown You only need to do this once *per session*. To re-run ThermoMPNN on a new protein, you may start on Step 3.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "# cleaning out any remaining data\n",
        "!cd /content\n",
        "!rm -rf /content/ThermoMPNN-D\n",
        "!rm -rf /content/sample_data\n",
        "!rm /content/*.pdb\n",
        "!rm /content/*.csv\n",
        "\n",
        "# import ThermoMPNN-D github repo\n",
        "import os\n",
        "if not os.path.exists(\"/content/ThermoMPNN-D\"):\n",
        "  !git clone https://github.com/Kuhlman-Lab/ThermoMPNN-D.git\n",
        "  %cd /content/ThermoMPNN-D\n",
        "\n",
        "# downloading various dependencies - add more if needed later\n",
        "! pip install omegaconf wandb pytorch-lightning biopython nglview\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zqSoIY9hfaae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e92b43-ac26-4897-9035-ea9b092eb467"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/*.csv': No such file or directory\n",
            "Cloning into 'ThermoMPNN-D'...\n",
            "remote: Enumerating objects: 1445, done.\u001b[K\n",
            "remote: Counting objects: 100% (149/149), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 1445 (delta 77), reused 102 (delta 58), pack-reused 1296 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1445/1445), 214.44 MiB | 19.03 MiB/s, done.\n",
            "Resolving deltas: 100% (768/768), done.\n",
            "/content/ThermoMPNN-D\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.3)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.10/dist-packages (1.84)\n",
            "Requirement already satisfied: nglview in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.2)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.16.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.6.1)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.4.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.12.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.11.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.26.4)\n",
            "Requirement already satisfied: ipywidgets>=8 in /usr/local/lib/python3.10/dist-packages (from nglview) (8.1.5)\n",
            "Requirement already satisfied: notebook>=7 in /usr/local/lib/python3.10/dist-packages (from nglview) (7.2.2)\n",
            "Requirement already satisfied: jupyterlab-widgets in /usr/local/lib/python3.10/dist-packages (from nglview) (3.0.13)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.10.9)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8->nglview) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8->nglview) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8->nglview) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8->nglview) (4.0.13)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=7->nglview) (2.14.2)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=7->nglview) (2.27.3)\n",
            "Requirement already satisfied: jupyterlab<4.3,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=7->nglview) (4.2.5)\n",
            "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /usr/local/lib/python3.10/dist-packages (from notebook>=7->nglview) (0.2.4)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=7->nglview) (6.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8->nglview) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8->nglview) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8->nglview) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8->nglview) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8->nglview) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8->nglview) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8->nglview) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8->nglview) (4.9.0)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook>=7->nglview) (3.7.1)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook>=7->nglview) (23.1.0)\n",
            "Requirement already satisfied: jupyter-client>=7.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook>=7->nglview) (8.6.3)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook>=7->nglview) (5.7.2)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook>=7->nglview) (0.10.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook>=7->nglview) (0.5.3)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook>=7->nglview) (6.5.4)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook>=7->nglview) (5.10.4)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook>=7->nglview) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook>=7->nglview) (0.21.0)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook>=7->nglview) (24.0.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook>=7->nglview) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook>=7->nglview) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook>=7->nglview) (1.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab<4.3,>=4.2.0->notebook>=7->nglview) (2.0.4)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab<4.3,>=4.2.0->notebook>=7->nglview) (0.27.2)\n",
            "Requirement already satisfied: ipykernel>=6.5.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab<4.3,>=4.2.0->notebook>=7->nglview) (6.29.5)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab<4.3,>=4.2.0->notebook>=7->nglview) (2.2.5)\n",
            "Requirement already satisfied: tomli>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab<4.3,>=4.2.0->notebook>=7->nglview) (2.0.2)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->notebook>=7->nglview) (2.16.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->notebook>=7->nglview) (0.9.25)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->notebook>=7->nglview) (4.23.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (1.2.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (21.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook>=7->nglview) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook>=7->nglview) (0.14.0)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab<4.3,>=4.2.0->notebook>=7->nglview) (1.6.6)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab<4.3,>=4.2.0->notebook>=7->nglview) (1.6.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8->nglview) (0.8.4)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=7->nglview) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=7->nglview) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=7->nglview) (0.20.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (2.8.2)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (2.0.7)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (0.1.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (2.20.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8->nglview) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8->nglview) (0.2.13)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (3.0.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (24.8.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (2.22)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=7->nglview) (2.9.0.20241003)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # **2. Set up ThermoMPNN imports and functions**\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "import sys\n",
        "from urllib import request\n",
        "from urllib.error import HTTPError\n",
        "from google.colab._message import MessageError\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from Bio.PDB import PDBParser\n",
        "from omegaconf import OmegaConf\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from scipy.spatial.distance import cdist\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "tMPNN_path = '/content/ThermoMPNN-D'\n",
        "if tMPNN_path not in sys.path:\n",
        "  sys.path.append(tMPNN_path)\n",
        "\n",
        "from thermompnn.datasets.dataset_utils import Mutation\n",
        "from thermompnn.datasets.v2_datasets import tied_featurize_mut\n",
        "from thermompnn.model.v2_model import batched_index_select, _dist\n",
        "\n",
        "from thermompnn.train_thermompnn import parse_cfg\n",
        "from thermompnn.trainer.v2_trainer import TransferModelPLv2, TransferModelPLv2Siamese\n",
        "\n",
        "def download_pdb(pdbcode, datadir, downloadurl=\"https://files.rcsb.org/download/\"):\n",
        "    \"\"\"\n",
        "    Downloads a PDB file from the Internet and saves it in a data directory.\n",
        "    :param pdbcode: The standard PDB ID e.g. '3ICB' or '3icb'\n",
        "    :param datadir: The directory where the downloaded file will be saved\n",
        "    :param downloadurl: The base PDB download URL, cf.\n",
        "        `https://www.rcsb.org/pages/download/http#structures` for details\n",
        "    :return: the full path to the downloaded PDB file or None if something went wrong\n",
        "    \"\"\"\n",
        "\n",
        "    pdbfn = pdbcode + \".pdb\"\n",
        "    url = downloadurl + pdbfn\n",
        "    outfnm = os.path.join(datadir, pdbfn)\n",
        "    try:\n",
        "        request.urlretrieve(url, outfnm)\n",
        "        return outfnm\n",
        "    except Exception as err:\n",
        "        print(str(err), file=sys.stderr)\n",
        "        return None\n",
        "\n",
        "def alt_parse_PDB_biounits(x, atoms=['N', 'CA', 'C'], chain=None):\n",
        "    '''\n",
        "  input:  x = PDB filename\n",
        "          atoms = atoms to extract (optional)\n",
        "  output: (length, atoms, coords=(x,y,z)), sequence\n",
        "  '''\n",
        "\n",
        "    alpha_1 = list(\"ARNDCQEGHILKMFPSTWYV-\")\n",
        "    states = len(alpha_1)\n",
        "    alpha_3 = ['ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'ILE',\n",
        "               'LEU', 'LYS', 'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL', 'GAP']\n",
        "\n",
        "    aa_1_N = {a: n for n, a in enumerate(alpha_1)}\n",
        "    aa_3_N = {a: n for n, a in enumerate(alpha_3)}\n",
        "    aa_N_1 = {n: a for n, a in enumerate(alpha_1)}\n",
        "    aa_1_3 = {a: b for a, b in zip(alpha_1, alpha_3)}\n",
        "    aa_3_1 = {b: a for a, b in zip(alpha_1, alpha_3)}\n",
        "\n",
        "    def AA_to_N(x):\n",
        "        # [\"ARND\"] -> [[0,1,2,3]]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 0: x = x[None]\n",
        "        return [[aa_1_N.get(a, states - 1) for a in y] for y in x]\n",
        "\n",
        "    def N_to_AA(x):\n",
        "        # [[0,1,2,3]] -> [\"ARND\"]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 1: x = x[None]\n",
        "        return [\"\".join([aa_N_1.get(a, \"-\") for a in y]) for y in x]\n",
        "\n",
        "    xyz, seq, min_resn, max_resn = {}, {}, 1e6, -1e6\n",
        "    resn_list = []\n",
        "    for line in open(x, \"rb\"):\n",
        "        line = line.decode(\"utf-8\", \"ignore\").rstrip()\n",
        "\n",
        "        # handling MSE and SEC residues\n",
        "        if line[:6] == \"HETATM\" and line[17:17 + 3] == \"MSE\":\n",
        "            line = line.replace(\"HETATM\", \"ATOM  \")\n",
        "            line = line.replace(\"MSE\", \"MET\")\n",
        "        elif line[17:17 + 3] == \"MSE\":\n",
        "            line = line.replace(\"MSE\", \"MET\")\n",
        "        elif line[17:17 + 3] == \"SEC\":\n",
        "            line = line.replace(\"SEC\", \"CYS\")\n",
        "\n",
        "        if line[:4] == \"ATOM\":\n",
        "            ch = line[21:22]\n",
        "            if ch == chain or chain is None:\n",
        "                atom = line[12:12 + 4].strip()\n",
        "                resi = line[17:17 + 3]\n",
        "                resn = line[22:22 + 5].strip()\n",
        "\n",
        "                # RAW resn is defined HERE\n",
        "                if resn not in resn_list:\n",
        "                  resn_list.append(resn) # NEED to keep ins code here\n",
        "                x, y, z = [float(line[i:(i + 8)]) for i in [30, 38, 46]]\n",
        "                if resn[-1].isalpha():\n",
        "                    resa, resn = resn[-1], int(resn[:-1]) - 1\n",
        "                else:\n",
        "                    resa, resn = \"\", int(resn) - 1\n",
        "                if resn < min_resn:\n",
        "                    min_resn = resn\n",
        "                if resn > max_resn:\n",
        "                    max_resn = resn\n",
        "                if resn not in xyz:\n",
        "                    xyz[resn] = {}\n",
        "                if resa not in xyz[resn]:\n",
        "                    xyz[resn][resa] = {}\n",
        "                if resn not in seq:\n",
        "                    seq[resn] = {}\n",
        "                if resa not in seq[resn]:\n",
        "                    seq[resn][resa] = resi\n",
        "\n",
        "                if atom not in xyz[resn][resa]:\n",
        "                    xyz[resn][resa][atom] = np.array([x, y, z])\n",
        "\n",
        "    # convert to numpy arrays, fill in missing values\n",
        "    seq_, xyz_ = [], []\n",
        "    try:\n",
        "        for resn in range(min_resn, max_resn + 1):\n",
        "            if resn in seq:\n",
        "              # CLEANED resn is defined HERE\n",
        "                # resn_list.append(str(resn + 1))\n",
        "                for k in sorted(seq[resn]): seq_.append(aa_3_N.get(seq[resn][k], 20))\n",
        "            else:\n",
        "                seq_.append(20)\n",
        "\n",
        "            if resn in xyz:\n",
        "                for k in sorted(xyz[resn]):\n",
        "                    for atom in atoms:\n",
        "                        if atom in xyz[resn][k]:\n",
        "                            xyz_.append(xyz[resn][k][atom])\n",
        "                        else:\n",
        "                            xyz_.append(np.full(3, np.nan))\n",
        "            else:\n",
        "                for atom in atoms: xyz_.append(np.full(3, np.nan))\n",
        "        return np.array(xyz_).reshape(-1, len(atoms), 3), N_to_AA(np.array(seq_)), list(dict.fromkeys(resn_list))\n",
        "    except TypeError:\n",
        "        return 'no_chain', 'no_chain', 'no_chain'\n",
        "\n",
        "def alt_parse_PDB(path_to_pdb, input_chain_list=None, ca_only=False, side_chains=False, mut_chain=None):\n",
        "    c = 0\n",
        "    pdb_dict_list = []\n",
        "    init_alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
        "                     'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n',\n",
        "                     'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "    extra_alphabet = [str(item) for item in list(np.arange(300))]\n",
        "    chain_alphabet = init_alphabet + extra_alphabet\n",
        "\n",
        "    if input_chain_list:\n",
        "        chain_alphabet = input_chain_list\n",
        "\n",
        "    biounit_names = [path_to_pdb]\n",
        "    for biounit in biounit_names:\n",
        "        my_dict = {}\n",
        "        s = 0\n",
        "        concat_seq = ''\n",
        "        concat_N = []\n",
        "        concat_CA = []\n",
        "        concat_C = []\n",
        "        concat_O = []\n",
        "        concat_mask = []\n",
        "        coords_dict = {}\n",
        "        for letter in chain_alphabet:\n",
        "            if ca_only:\n",
        "                sidechain_atoms = ['CA']\n",
        "            elif side_chains:\n",
        "                sidechain_atoms = [\"N\", \"CA\", \"C\", \"O\", \"CB\",\n",
        "                                   \"CG\", \"CG1\", \"OG1\", \"OG2\", \"CG2\", \"OG\", \"SG\",\n",
        "                                   \"CD\", \"SD\", \"CD1\", \"ND1\", \"CD2\", \"OD1\", \"OD2\", \"ND2\",\n",
        "                                   \"CE\", \"CE1\", \"NE1\", \"OE1\", \"NE2\", \"OE2\", \"NE\", \"CE2\", \"CE3\",\n",
        "                                   \"NZ\", \"CZ\", \"CZ2\", \"CZ3\", \"CH2\", \"OH\", \"NH1\", \"NH2\"]\n",
        "            else:\n",
        "                sidechain_atoms = ['N', 'CA', 'C', 'O']\n",
        "            xyz, seq, resn_list = alt_parse_PDB_biounits(biounit, atoms=sidechain_atoms, chain=letter)\n",
        "            if resn_list != 'no_chain':\n",
        "              my_dict['resn_list_' + letter] = resn_list\n",
        "                  # my_dict['resn_list'] = list(resn_list)\n",
        "            if type(xyz) != str:\n",
        "                concat_seq += seq[0]\n",
        "                my_dict['seq_chain_' + letter] = seq[0]\n",
        "                coords_dict_chain = {}\n",
        "                if ca_only:\n",
        "                    coords_dict_chain['CA_chain_' + letter] = xyz.tolist()\n",
        "                elif side_chains:\n",
        "                    coords_dict_chain['SG_chain_' + letter] = xyz[:, 11].tolist()\n",
        "                else:\n",
        "                    coords_dict_chain['N_chain_' + letter] = xyz[:, 0, :].tolist()\n",
        "                    coords_dict_chain['CA_chain_' + letter] = xyz[:, 1, :].tolist()\n",
        "                    coords_dict_chain['C_chain_' + letter] = xyz[:, 2, :].tolist()\n",
        "                    coords_dict_chain['O_chain_' + letter] = xyz[:, 3, :].tolist()\n",
        "                my_dict['coords_chain_' + letter] = coords_dict_chain\n",
        "                s += 1\n",
        "\n",
        "        fi = biounit.rfind(\"/\")\n",
        "        # if mut_chain is None:\n",
        "          # my_dict['resn_list'] = list(resn_list)\n",
        "        my_dict['name'] = biounit[(fi + 1):-4]\n",
        "        my_dict['num_of_chains'] = s\n",
        "        my_dict['seq'] = concat_seq\n",
        "        # my_dict['resn_list'] = list(resn_list)\n",
        "        if s <= len(chain_alphabet):\n",
        "            pdb_dict_list.append(my_dict)\n",
        "            c += 1\n",
        "    return pdb_dict_list\n",
        "\n",
        "def get_chains_from_pdb(pdb_file):\n",
        "  parser = PDBParser(QUIET=True)\n",
        "  structure = parser.get_structure('', pdb_file)\n",
        "  return [c.id for c in structure.get_chains()]\n",
        "\n",
        "def get_chains(pdb_file, chain_list):\n",
        "  # collect list of chains in PDB to match with input\n",
        "  pdb_chains = get_chains_from_pdb(pdb_file)\n",
        "  if len(chain_list) < 1: # fill in all chains if left blank\n",
        "    chain_list = pdb_chains\n",
        "\n",
        "  for ch in chain_list:\n",
        "    assert ch in pdb_chains, f\"Chain {ch} not found in PDB file with chains {pdb_chains}\"\n",
        "\n",
        "  return chain_list\n",
        "\n"
      ],
      "metadata": {
        "id": "3Lgz5km3gFyv",
        "cellView": "form"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "#@title # **3. Upload or Fetch Input Data**\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "import sys\n",
        "from urllib import request\n",
        "from urllib.error import HTTPError\n",
        "from google.colab._message import MessageError\n",
        "\n",
        "#@markdown ## You may either specify a PDB code to fetch or upload a custom PDB file.<br><br>\n",
        "\n",
        "# -------- Collecting Settings for ThermoMPNN run --------- #\n",
        "\n",
        "!rm /content/*.pdb &> /dev/null\n",
        "\n",
        "#@markdown PDB code (example: 1PGA):\n",
        "PDB = \"1bvc\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Upload Custom PDB?\n",
        "Custom = False #@param {type: \"boolean\"}\n",
        "#@markdown NOTE: If enabled, a `Choose files` button will appear at the bottom of this cell once this cell is run.\n",
        "\n",
        "#@markdown Chain(s) of Interest (example: A,B,C):\n",
        "Chains = \"\" #@param {type:\"string\"}\n",
        "#@markdown If left empty, all chains will be used.\n",
        "\n",
        "# try to upload the PDB file to Colab servers\n",
        "if Custom:\n",
        "  try:\n",
        "    uploaded_pdb = files.upload()\n",
        "    for fn in uploaded_pdb.keys():\n",
        "      PDB = os.path.basename(fn)\n",
        "      if not PDB.endswith('.pdb'):\n",
        "        raise ValueError(f\"Uploaded file {PDB} does not end in '.pdb'. Please check and rename file as needed.\")\n",
        "      os.rename(fn, os.path.join(\"/content/\", PDB))\n",
        "      pdb_file = os.path.join(\"/content/\", PDB)\n",
        "  except (MessageError, FileNotFoundError):\n",
        "    print('\\n', '*' * 100, '\\n')\n",
        "    print('Sorry, your input file failed to upload. Please try the backup upload procedure (next cell).')\n",
        "\n",
        "else:\n",
        "  try:\n",
        "    fn = download_pdb(PDB, \"/content/\")\n",
        "    if fn is None:\n",
        "      raise ValueError(\"Failed to fetch PDB from RSCB. Please double-check PDB code and try again.\")\n",
        "    else:\n",
        "      pdb_file = fn\n",
        "  except HTTPError:\n",
        "    raise HTTPError(f\"No protein with code {PDB} exists in RSCB PDB. Please double-check PDB code and try again.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WPhbnMAHf1qL"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # **3. Backup Data Upload (ONLY needed if initial upload failed)**\n",
        "\n",
        "#@markdown ## Colab automatic file uploads are not very reliable. If your file failed to upload automatically, you can do so manually by following these steps.<br><br>\n",
        "\n",
        "#@markdown #### 1. Click the \"Files\" icon on the left toolbar. This will open the Colab server file folder.\n",
        "\n",
        "#@markdown #### 2. The only thing in this folder should be \"ThermoMPNN\" directory. If any other files are in here, delete them.\n",
        "\n",
        "#@markdown #### 3. Click the \"Upload to session storage\" button under the \"Files\" header. Choose your file for upload.\n",
        "\n",
        "#@markdown #### 4. Run this cell. ThermoMPNN will find your file in session storage and use it.\n",
        "\n",
        "\n",
        "#@markdown Chain(s) of Interest (example: A,B,C):\n",
        "Chains = \"A\" #@param {type:\"string\"}\n",
        "#@markdown If left empty, all chains will be used.\n",
        "\n",
        "PDB = \"\"\n",
        "\n",
        "files = sorted(os.listdir('/content/'))\n",
        "files = [f for f in files if f.endswith('.pdb')]\n",
        "\n",
        "if len(files) < 1:\n",
        "  raise ValueError('No PDB file found. Please upload your file before running this cell. Make sure it has a .pdb suffix.')\n",
        "elif len(files) > 1:\n",
        "  raise ValueError('Too many PDB files found. Please clear out any other PDBs before running this cell.')\n",
        "else:\n",
        "  pdb_file = os.path.join(\"/content/\", files[0])\n",
        "  PDB = files[0].removesuffix('.pdb')\n",
        "  print('Successfully uploaded PDB file %s' % (files[0]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RjdyW_tmglI1",
        "outputId": "552ef0f2-8a2c-4c44-c6e6-e356b7ae499b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded PDB file 1bvc.pdb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **4. Run Model**\n",
        "\n",
        "#@markdown Stability model to use:\n",
        "Model = \"Single\" #@param [\"Epistatic\", \"Additive\", \"Single\"]\n",
        "\n",
        "#@markdown ---------------\n",
        "#@markdown Include Cysteines?\n",
        "Include = False #@param {type: \"boolean\"}\n",
        "#@markdown NOTE: Due to assay artifacts surrounding disulfide formation, model predictions for surface cysteine mutations may be overly favorable.\n",
        "\n",
        "#@markdown Explicitly penalize disulfide breakage? Recommended.\n",
        "Penalize = False #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown --------------\n",
        "\n",
        "BatchSize = 2048 #@param {type: \"integer\"}\n",
        "#@markdown Recommended: 256 (single/additive) or 2048 (epistatic). Should be lowered if you hit a memory error.\n",
        "\n",
        "Threshold = -0.5 #@param {type: \"number\"}\n",
        "#@markdown Ignored for single mutant model. Only mutations BELOW (more stable than) this threshold are kept. This is useful for speed and memory, since double mutation data grows exponentially.\n",
        "\n",
        "Distance = 10.0 #@param {type: \"number\"}\n",
        "#@markdown Ignored for single mutant model. Only mutation pairs BELOW (within) this distance (in Angstrom) are kept. Useful for speed and memory savings.\n",
        "\n",
        "# ---------- PARSE OPTIONS -------------- #\n",
        "\n",
        "# use input_chain_list to grab correct protein chain\n",
        "chain_list = Chains.strip().split(',')\n",
        "if len(chain_list) == 1 and chain_list[0] == '':\n",
        "  chain_list = []\n",
        "\n",
        "# validate chain inputs\n",
        "chain_list = get_chains(pdb_file, chain_list)\n",
        "\n",
        "# remove cys from alphabet if needed\n",
        "alphabet = 'ACDEFGHIKLMNPQRSTVWY' if Include else 'ADEFGHIKLMNPQRSTVWY'\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-bxta5Lvgheo",
        "cellView": "form"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # **Run SSM inference**\n",
        "\n",
        "from v2_ssm import get_config, format_output_single, format_output_double, get_ssm_mutations_double, SSMDataset, run_double, format_output_epistatic\n",
        "import argparse\n",
        "\n",
        "\n",
        "def run_single(cfg, model, pdb):\n",
        "    \"\"\"Runs single-mutant SSM sweep with ThermoMPNN v2\"\"\"\n",
        "\n",
        "    stime = time.time()\n",
        "\n",
        "    pdb[0]['mutation'] = Mutation([0], ['A'], ['A'], [0.], '') # placeholder mutation to keep featurization from throwing error\n",
        "\n",
        "    # featurize input\n",
        "    device = 'cuda'\n",
        "    batch = tied_featurize_mut(pdb)\n",
        "    X, S, mask, lengths, chain_M, chain_encoding_all, residue_idx, mut_positions, mut_wildtype_AAs, mut_mutant_AAs, mut_ddGs, atom_mask = batch\n",
        "\n",
        "    X = X.to(device)\n",
        "    S = S.to(device)\n",
        "    mask = mask.to(device)\n",
        "    lengths = torch.Tensor(lengths).to(device)\n",
        "    chain_M = chain_M.to(device)\n",
        "    chain_encoding_all = chain_encoding_all.to(device)\n",
        "    residue_idx = residue_idx.to(device)\n",
        "    mut_ddGs = mut_ddGs.to(device)\n",
        "\n",
        "    # do single pass through thermompnn\n",
        "    X = torch.nan_to_num(X, nan=0.0)\n",
        "    all_mpnn_hid, mpnn_embed, _, mpnn_edges = model.prot_mpnn(X, S, mask, chain_M, residue_idx, chain_encoding_all)\n",
        "\n",
        "    all_mpnn_hid = torch.cat(all_mpnn_hid[:cfg.model.num_final_layers], -1)\n",
        "    all_mpnn_hid = torch.squeeze(torch.cat([all_mpnn_hid, mpnn_embed], -1), 0) # [L, E]\n",
        "\n",
        "    all_mpnn_hid = model.light_attention(torch.unsqueeze(all_mpnn_hid, -1))\n",
        "\n",
        "    ddg = model.ddg_out(all_mpnn_hid) # [L, 21]\n",
        "\n",
        "    # subtract wildtype ddgs to normalize\n",
        "    S = torch.squeeze(S) # [L, ]\n",
        "\n",
        "    wt_ddg = batched_index_select(ddg, dim=-1, index=S) # [L, 1]\n",
        "    ddg = ddg - wt_ddg.expand(-1, 21) # [L, 21]\n",
        "    etime = time.time()\n",
        "    elapsed = etime - stime\n",
        "    length = ddg.shape[0]\n",
        "    print(f'ThermoMPNN single mutant predictions generated in {round(elapsed, 2)} seconds.')\n",
        "    return ddg, S\n",
        "\n",
        "\n",
        "def run_epistatic(config, model, pdb, BatchSize, Threshold):\n",
        "    \"\"\"Run epistatic model on double mutations \"\"\"\n",
        "\n",
        "    stime = time.time()\n",
        "\n",
        "    pdb[0]['mutation'] = Mutation([0], ['A'], ['A'], [0.], '') # placeholder mutation to keep featurization from throwing error\n",
        "\n",
        "    # featurize input\n",
        "    device = 'cuda'\n",
        "    batch = tied_featurize_mut(pdb)\n",
        "    X, S, mask, lengths, chain_M, chain_encoding_all, residue_idx, mut_positions, mut_wildtype_AAs, mut_mutant_AAs, mut_ddGs, atom_mask = batch\n",
        "\n",
        "    X = X.to(device)\n",
        "    S = S.to(device)\n",
        "    mask = mask.to(device)\n",
        "    lengths = torch.Tensor(lengths).to(device)\n",
        "    chain_M = chain_M.to(device)\n",
        "    chain_encoding_all = chain_encoding_all.to(device)\n",
        "    residue_idx = residue_idx.to(device)\n",
        "    mut_ddGs = mut_ddGs.to(device)\n",
        "\n",
        "    # do single pass through thermompnn\n",
        "    X = torch.nan_to_num(X, nan=0.0)\n",
        "    all_mpnn_hid, mpnn_embed, _, mpnn_edges = model.prot_mpnn(X, S, mask, chain_M, residue_idx, chain_encoding_all)\n",
        "\n",
        "    # grab double mutation inputs\n",
        "    MUT_POS, MUT_WT_AA, MUT_MUT_AA = get_ssm_mutations_double(pdb[0])\n",
        "    dataset = SSMDataset(MUT_POS, MUT_WT_AA, MUT_MUT_AA)\n",
        "    loader = DataLoader(dataset, shuffle=False, batch_size=BatchSize, num_workers=8)\n",
        "\n",
        "    args = {'batch_size': BatchSize, 'threshold': Threshold}\n",
        "    args = argparse.Namespace(**args)\n",
        "    preds = run_double(all_mpnn_hid, mpnn_embed, config, loader, args, model, X, mask, mpnn_edges)\n",
        "    ddg, mutations = format_output_epistatic(preds, S, MUT_POS, MUT_WT_AA, MUT_MUT_AA, args.threshold)\n",
        "\n",
        "    etime = time.time()\n",
        "    elapsed = etime - stime\n",
        "    print(f'ThermoMPNN double mutant epistatic model predictions generated in {round(elapsed, 2)} seconds.')\n",
        "    return ddg, mutations\n",
        "\n",
        "\n",
        "def renumber_pdb(df, pdb, Model):\n",
        "    \"\"\"Renumber output mutations to match PDB numbering for interpretation\"\"\"\n",
        "    # parse PDB\n",
        "    if (Model == 'Additive') or (Model == 'Epistatic'):\n",
        "        # grab positions\n",
        "        df[['mut1', 'mut2']] = df['Mutation'].str.split(':', n=2, expand=True)\n",
        "        df['pos1'] = df['mut1'].str[1:-1].astype(int) - 1\n",
        "        df['pos2'] = df['mut2'].str[1:-1].astype(int) - 1\n",
        "\n",
        "        df['pos1'] = idx_to_pdb_num(pdb, df['pos1'].values)\n",
        "        df['pos2'] = idx_to_pdb_num(pdb, df['pos2'].values)\n",
        "\n",
        "        df['wt1'], df['wt2'] = df['mut1'].str[0], df['mut2'].str[0]\n",
        "        df['mt1'], df['mt2'] = df['mut1'].str[-1], df['mut2'].str[-1]\n",
        "\n",
        "        df['Mutation'] = df['wt1'] + df['pos1'] + df['mt1'] + ':' + df['wt2'] + df['pos2'] + df['mt2']\n",
        "        df = df[['ddG (kcal/mol)', 'Mutation', 'CA-CA Distance']].reset_index(drop=True)\n",
        "\n",
        "    else:\n",
        "        # grab position\n",
        "        df['pos'] = df['Mutation'].str[1:-1].astype(int) - 1\n",
        "\n",
        "        df['pos1'] = idx_to_pdb_num(pdb, df['pos'].values)\n",
        "\n",
        "        df['wt1'] = df['Mutation'].str[0]\n",
        "        df['mt1'] = df['Mutation'].str[-1]\n",
        "\n",
        "        df['Mutation'] = df['wt1'] + df['pos1'] + df['mt1']\n",
        "        df = df[['ddG (kcal/mol)', 'Mutation']].reset_index(drop=True)\n",
        "\n",
        "    print(f'ThermoMPNN predictions renumbered.')\n",
        "    return df\n",
        "\n",
        "\n",
        "def distance_filter(df, pdb, Distance):\n",
        "    \"\"\"filter df based on pdb distances\"\"\"\n",
        "\n",
        "    # grab positions\n",
        "    df[['mut1', 'mut2']] = df['Mutation'].str.split(':', n=2, expand=True)\n",
        "    df['pos1'] = df['mut1'].str[1:-1].astype(int) - 1\n",
        "    df['pos2'] = df['mut2'].str[1:-1].astype(int) - 1\n",
        "\n",
        "    # get distance matrix\n",
        "    coords = [k for k in pdb.keys() if k.startswith('coords_chain_')]\n",
        "    assert len(coords) < 2\n",
        "\n",
        "    for coord in coords:\n",
        "        ch = coord.split('_')[-1]\n",
        "        coo = pdb[coord][f'N_chain_{ch}']\n",
        "        coo = np.stack(coo) # [L, 3]\n",
        "        dmat = cdist(coo, coo) # [L, L]\n",
        "\n",
        "    # filter df based on positions\n",
        "    pos1, pos2 = df['pos1'].values, df['pos2'].values\n",
        "    dist_list = []\n",
        "    for p1, p2 in tqdm(zip(pos1, pos2)):\n",
        "        dist_list.append(dmat[p1, p2])\n",
        "\n",
        "    df['CA-CA Distance'] = dist_list\n",
        "    df = df.loc[df['CA-CA Distance'] <= Distance]\n",
        "    df['CA-CA Distance'] = df['CA-CA Distance'].round(2)\n",
        "\n",
        "    df = df[['ddG (kcal/mol)', 'Mutation', 'CA-CA Distance']].reset_index(drop=True)\n",
        "    print(f'Distance matrix generated.')\n",
        "    return df\n",
        "\n",
        "\n",
        "def idx_to_pdb_num(pdb, poslist):\n",
        "        # set up PDB resns and boundaries\n",
        "    chains = [key[-1] for key in pdb.keys() if key.startswith('resn_list_')]\n",
        "    resn_lists = [pdb[key] for key in pdb.keys() if key.startswith('resn_list')]\n",
        "    converter = {}\n",
        "    offset = 0\n",
        "    for n, rlist in enumerate(resn_lists):\n",
        "        chain = chains[n]\n",
        "        for idx, resid in enumerate(rlist):\n",
        "            converter[idx + offset] = chain + resid\n",
        "        offset += idx + 1\n",
        "    return [converter[pos] for pos in poslist]\n",
        "\n",
        "\n",
        "def disulfide_penalty(df, pdb_file, chain_list, Model):\n",
        "  \"\"\"Automatically detects disulfide breakage based on Cys-Cys distance.\"\"\"\n",
        "\n",
        "  pdb_dict = alt_parse_PDB(pdb_file, input_chain_list=chain_list, side_chains=True)\n",
        "\n",
        "  # collect all SG coordinates from all chains\n",
        "  coords_all = [k for k in pdb_dict[0].keys() if k.startswith('coords')]\n",
        "  chains = [c[-1] for c in coords_all]\n",
        "  sg_coords = [pdb_dict[0][c][f'SG_chain_{chain}'] for c, chain in zip(coords_all, chains)]\n",
        "  sg_coords = np.concatenate(sg_coords, axis=0)\n",
        "\n",
        "  # calculate pairwise distance and threshold to find disulfides\n",
        "  dist = cdist(sg_coords, sg_coords)\n",
        "  dist = np.nan_to_num(dist, 10000)\n",
        "  hits = np.where((dist < 3) & (dist > 0)) # tuple of two [N] arrays of indices\n",
        "\n",
        "  if Model == 'Single':\n",
        "    df['wtAA'] = df['Mutation'].str[0]\n",
        "    df['mutAA'] = df['Mutation'].str[-1]\n",
        "    df['pos'] = df['Mutation'].str[1:-1].astype(int) - 1\n",
        "\n",
        "    # match hit indices to actual resns for penalty\n",
        "    bad_resns = []\n",
        "    for h in hits[0]:\n",
        "      bad_resns.append(h)\n",
        "\n",
        "    print('Identified the following disulfide engaged residues:', bad_resns)\n",
        "\n",
        "    # apply penalty\n",
        "    penalty = 2  # in kcal/mol - higher is less stable\n",
        "    mask = df['pos'].isin(bad_resns) & (df['wtAA'] != df['mutAA'])\n",
        "\n",
        "    df.loc[mask, 'ddG (kcal/mol)'] = df.loc[mask, 'ddG (kcal/mol)'] + penalty\n",
        "    return df[['Mutation', 'ddG (kcal/mol)']].reset_index(drop=True)\n",
        "\n",
        "  else:\n",
        "    df[['mut1', 'mut2']] = df['Mutation'].str.split(':', n=2, expand=True)\n",
        "    df['wtAA1'] = df['mut1'].str[0]\n",
        "    df['mutAA1'] = df['mut1'].str[-1]\n",
        "    df['pos1'] = df['mut1'].str[1:-1].astype(int) - 1\n",
        "\n",
        "    df['wtAA2'] = df['mut2'].str[0]\n",
        "    df['mutAA2'] = df['mut2'].str[-1]\n",
        "    df['pos2'] = df['mut2'].str[1:-1].astype(int) - 1\n",
        "\n",
        "    bad_resns = []\n",
        "    for h in hits[0]:\n",
        "      bad_resns.append(h)\n",
        "\n",
        "    print('Identified the following disulfide engaged residues:', bad_resns)\n",
        "\n",
        "    # apply penalty\n",
        "    penalty = 2  # in kcal/mol - higher is less stable\n",
        "    mask = df['pos1'].isin(bad_resns) & (df['wtAA1'] != df['mutAA1'])\n",
        "    mask2 = df['pos2'].isin(bad_resns) & (df['wtAA2'] != df['mutAA2'])\n",
        "    mask = mask | mask2\n",
        "\n",
        "\n",
        "    df.loc[mask, 'ddG (kcal/mol)'] = df.loc[mask, 'ddG (kcal/mol)'] + penalty\n",
        "    return df[['Mutation', 'ddG (kcal/mol)', 'CA-CA Distance']].reset_index(drop=True)\n",
        "\n",
        "\n",
        "# load config automatically\n",
        "\n",
        "config = get_config(Model.lower())\n",
        "config.platform.thermompnn_dir = '/content/ThermoMPNN-D'\n",
        "\n",
        "if Model == 'Single' or Model == 'Additive':\n",
        "  # load model\n",
        "  model_path = '/content/ThermoMPNN-D/model_weights/ThermoMPNN-ens1.ckpt'\n",
        "  model = TransferModelPLv2.load_from_checkpoint(checkpoint_path=model_path, cfg=config, device='gpu').model\n",
        "  model.eval()\n",
        "  model.cuda()\n",
        "\n",
        "  # run inference routine\n",
        "  pdb = alt_parse_PDB(pdb_file, chain_list)\n",
        "  ddg, S = run_single(config, model, pdb)\n",
        "\n",
        "  if Model == 'Single':\n",
        "    ddg, mutations = format_output_single(ddg, S, Threshold)\n",
        "  elif Model == 'Additive':\n",
        "    ddg, mutations = format_output_double(ddg, S, Threshold)\n",
        "\n",
        "else:\n",
        "  # load model\n",
        "  model_path = '/content/ThermoMPNN-D/model_weights/ThermoMPNN-D-ens1.ckpt'\n",
        "  model = TransferModelPLv2Siamese.load_from_checkpoint(model_path, cfg=config, device='gpu').model\n",
        "  model.eval()\n",
        "  model.cuda()\n",
        "\n",
        "  # run inference routine\n",
        "  pdb = alt_parse_PDB(pdb_file, chain_list)\n",
        "  ddg, mutations = run_epistatic(config, model, pdb, BatchSize, Threshold)\n",
        "\n",
        "# compile output dataframe and sort/filter it\n",
        "df = pd.DataFrame({\n",
        "    'ddG (kcal/mol)': ddg,\n",
        "    'Mutation': mutations\n",
        "})\n",
        "\n",
        "df['ddG (kcal/mol)'] = df['ddG (kcal/mol)'].round(4)\n",
        "\n",
        "if Model != 'Single':\n",
        "    df = distance_filter(df, pdb[0], Distance)\n",
        "\n",
        "if Penalize:\n",
        "  df = disulfide_penalty(df, pdb_file, chain_list, Model)\n",
        "\n",
        "df = df.dropna(subset=['ddG (kcal/mol)'])\n",
        "if Threshold <= 0.:\n",
        "  df = df.sort_values(by=['ddG (kcal/mol)'])\n",
        "\n",
        "if Model != 'Single': # sort to have same output order\n",
        "    df[['mut1', 'mut2']] = df['Mutation'].str.split(':', n=2, expand=True)\n",
        "    df['pos1'] = df['mut1'].str[1:-1].astype(int) + 1\n",
        "    df['pos2'] = df['mut2'].str[1:-1].astype(int) + 1\n",
        "\n",
        "    df = df.sort_values(by=['pos1', 'pos2'])\n",
        "    df = df[['ddG (kcal/mol)', 'Mutation', 'CA-CA Distance']].reset_index(drop=True)\n",
        "\n",
        "try:\n",
        "  df = renumber_pdb(df, pdb[0], Model)\n",
        "except IndexError:\n",
        "  print('PDB renumbering failed (sorry!) You can still use the raw position data. Or, you can renumber your PDB, fill any weird gaps, and try again.')\n"
      ],
      "metadata": {
        "id": "qisnoLI-iddh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ce48a5e-06f5-4505-83b5-2b6252c52754",
        "cellView": "form"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/ThermoMPNN-D/thermompnn/model/modules.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model %s /content/ThermoMPNN-D/vanilla_model_weights/v_48_020.pt\n",
            "setting ProteinMPNN dropout: 0.0\n",
            "MLP HIDDEN SIZES: [384, 64, 32, 21]\n",
            "ThermoMPNN single mutant predictions generated in 0.02 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:00, 14501.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ThermoMPNN predictions renumbered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Visualize data in an interactive table**\n",
        "from google.colab import data_table\n",
        "\n",
        "data_table.enable_dataframe_formatter()\n",
        "data_table.DataTable(df, include_index=True, num_rows_per_page=10)"
      ],
      "metadata": {
        "id": "rpdMGazKO0g1",
        "outputId": "9c5b30eb-62e6-4849-c8b1-00571e081339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ddG (kcal/mol)</th>\n",
              "      <th>Mutation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.8816</td>\n",
              "      <td>HA24W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.8641</td>\n",
              "      <td>HA93W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.8498</td>\n",
              "      <td>HA24F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.7902</td>\n",
              "      <td>HA93F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.7076</td>\n",
              "      <td>RA31W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.6830</td>\n",
              "      <td>HA119F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.6440</td>\n",
              "      <td>HA116R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.5990</td>\n",
              "      <td>HA24Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.5978</td>\n",
              "      <td>TA39I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.5866</td>\n",
              "      <td>HA24I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.5738</td>\n",
              "      <td>GA73L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-0.5706</td>\n",
              "      <td>HA64F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>-0.5625</td>\n",
              "      <td>RA31Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>-0.5546</td>\n",
              "      <td>QA26I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-0.5500</td>\n",
              "      <td>GA73I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-0.5378</td>\n",
              "      <td>NA132R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-0.5345</td>\n",
              "      <td>VA13I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>-0.5336</td>\n",
              "      <td>QA26M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>-0.5288</td>\n",
              "      <td>KA145L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>-0.5181</td>\n",
              "      <td>GA129C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>-0.5008</td>\n",
              "      <td>HA93Y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/81954c9606dcf997/data_table.js\";\n\n      const table = window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': -0.881600022315979,\n            'f': \"-0.881600022315979\",\n        },\n\"HA24W\"],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': -0.8640999794006348,\n            'f': \"-0.8640999794006348\",\n        },\n\"HA93W\"],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': -0.8497999906539917,\n            'f': \"-0.8497999906539917\",\n        },\n\"HA24F\"],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': -0.7901999950408936,\n            'f': \"-0.7901999950408936\",\n        },\n\"HA93F\"],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': -0.7075999975204468,\n            'f': \"-0.7075999975204468\",\n        },\n\"RA31W\"],\n [{\n            'v': 5,\n            'f': \"5\",\n        },\n{\n            'v': -0.6830000281333923,\n            'f': \"-0.6830000281333923\",\n        },\n\"HA119F\"],\n [{\n            'v': 6,\n            'f': \"6\",\n        },\n{\n            'v': -0.6439999938011169,\n            'f': \"-0.6439999938011169\",\n        },\n\"HA116R\"],\n [{\n            'v': 7,\n            'f': \"7\",\n        },\n{\n            'v': -0.5989999771118164,\n            'f': \"-0.5989999771118164\",\n        },\n\"HA24Y\"],\n [{\n            'v': 8,\n            'f': \"8\",\n        },\n{\n            'v': -0.5978000164031982,\n            'f': \"-0.5978000164031982\",\n        },\n\"TA39I\"],\n [{\n            'v': 9,\n            'f': \"9\",\n        },\n{\n            'v': -0.5866000056266785,\n            'f': \"-0.5866000056266785\",\n        },\n\"HA24I\"],\n [{\n            'v': 10,\n            'f': \"10\",\n        },\n{\n            'v': -0.5738000273704529,\n            'f': \"-0.5738000273704529\",\n        },\n\"GA73L\"],\n [{\n            'v': 11,\n            'f': \"11\",\n        },\n{\n            'v': -0.5705999732017517,\n            'f': \"-0.5705999732017517\",\n        },\n\"HA64F\"],\n [{\n            'v': 12,\n            'f': \"12\",\n        },\n{\n            'v': -0.5625,\n            'f': \"-0.5625\",\n        },\n\"RA31Y\"],\n [{\n            'v': 13,\n            'f': \"13\",\n        },\n{\n            'v': -0.5546000003814697,\n            'f': \"-0.5546000003814697\",\n        },\n\"QA26I\"],\n [{\n            'v': 14,\n            'f': \"14\",\n        },\n{\n            'v': -0.550000011920929,\n            'f': \"-0.550000011920929\",\n        },\n\"GA73I\"],\n [{\n            'v': 15,\n            'f': \"15\",\n        },\n{\n            'v': -0.5378000140190125,\n            'f': \"-0.5378000140190125\",\n        },\n\"NA132R\"],\n [{\n            'v': 16,\n            'f': \"16\",\n        },\n{\n            'v': -0.534500002861023,\n            'f': \"-0.534500002861023\",\n        },\n\"VA13I\"],\n [{\n            'v': 17,\n            'f': \"17\",\n        },\n{\n            'v': -0.5335999727249146,\n            'f': \"-0.5335999727249146\",\n        },\n\"QA26M\"],\n [{\n            'v': 18,\n            'f': \"18\",\n        },\n{\n            'v': -0.5288000106811523,\n            'f': \"-0.5288000106811523\",\n        },\n\"KA145L\"],\n [{\n            'v': 19,\n            'f': \"19\",\n        },\n{\n            'v': -0.5181000232696533,\n            'f': \"-0.5181000232696533\",\n        },\n\"GA129C\"],\n [{\n            'v': 20,\n            'f': \"20\",\n        },\n{\n            'v': -0.5008000135421753,\n            'f': \"-0.5008000135421753\",\n        },\n\"HA93Y\"]],\n        columns: [[\"number\", \"index\"], [\"number\", \"ddG (kcal/mol)\"], [\"string\", \"Mutation\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 10,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n\n      function appendQuickchartButton(parentElement) {\n        let quickchartButtonContainerElement = document.createElement('div');\n        quickchartButtonContainerElement.innerHTML = `\n<div id=\"df-6800291c-22ea-4402-9109-145d43e5c98c\">\n  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6800291c-22ea-4402-9109-145d43e5c98c')\"\n            title=\"Suggest charts\"\n            style=\"display:none;\">\n    \n<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n     width=\"24px\">\n    <g>\n        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n    </g>\n</svg>\n  </button>\n  \n<style>\n  .colab-df-quickchart {\n      --bg-color: #E8F0FE;\n      --fill-color: #1967D2;\n      --hover-bg-color: #E2EBFA;\n      --hover-fill-color: #174EA6;\n      --disabled-fill-color: #AAA;\n      --disabled-bg-color: #DDD;\n  }\n\n  [theme=dark] .colab-df-quickchart {\n      --bg-color: #3B4455;\n      --fill-color: #D2E3FC;\n      --hover-bg-color: #434B5C;\n      --hover-fill-color: #FFFFFF;\n      --disabled-bg-color: #3B4455;\n      --disabled-fill-color: #666;\n  }\n\n  .colab-df-quickchart {\n    background-color: var(--bg-color);\n    border: none;\n    border-radius: 50%;\n    cursor: pointer;\n    display: none;\n    fill: var(--fill-color);\n    height: 32px;\n    padding: 0;\n    width: 32px;\n  }\n\n  .colab-df-quickchart:hover {\n    background-color: var(--hover-bg-color);\n    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n    fill: var(--button-hover-fill-color);\n  }\n\n  .colab-df-quickchart-complete:disabled,\n  .colab-df-quickchart-complete:disabled:hover {\n    background-color: var(--disabled-bg-color);\n    fill: var(--disabled-fill-color);\n    box-shadow: none;\n  }\n\n  .colab-df-spinner {\n    border: 2px solid var(--fill-color);\n    border-color: transparent;\n    border-bottom-color: var(--fill-color);\n    animation:\n      spin 1s steps(1) infinite;\n  }\n\n  @keyframes spin {\n    0% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n      border-left-color: var(--fill-color);\n    }\n    20% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    30% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n      border-right-color: var(--fill-color);\n    }\n    40% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    60% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n    }\n    80% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-bottom-color: var(--fill-color);\n    }\n    90% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n    }\n  }\n</style>\n\n  <script>\n    async function quickchart(key) {\n      const quickchartButtonEl =\n        document.querySelector('#' + key + ' button');\n      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n      quickchartButtonEl.classList.add('colab-df-spinner');\n      try {\n        const charts = await google.colab.kernel.invokeFunction(\n            'suggestCharts', [key], {});\n      } catch (error) {\n        console.error('Error during call to suggestCharts:', error);\n      }\n      quickchartButtonEl.classList.remove('colab-df-spinner');\n      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n    }\n    (() => {\n      let quickchartButtonEl =\n        document.querySelector('#df-6800291c-22ea-4402-9109-145d43e5c98c button');\n      quickchartButtonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n    })();\n  </script>\n</div>`;\n        parentElement.appendChild(quickchartButtonContainerElement);\n      }\n\n      appendQuickchartButton(table);\n    ",
            "text/plain": [
              "<google.colab.data_table.DataTable object>"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # **Save Output as CSV**\n",
        "\n",
        "# ---------- Collect output into DF and save as CSV ---------- #\n",
        "from google.colab import files\n",
        "\n",
        "#@markdown Specify prefix for file saving (e.g., MyProtein). Leave blank to use input PDB code.\n",
        "PREFIX = \"test\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown NOTE: If you wish to retrieve your files manually, you may do so in the **Files** tab in the leftmost toolbar.\n",
        "\n",
        "#@markdown NOTE: Make sure you click \"Allow\" if your browser asks to permit downloads at this step.\n",
        "\n",
        "#@markdown Verbose output? This means saving more individual columns\n",
        "VERBOSE = True\n",
        "\n",
        "df['ddG (kcal/mol)'] = df['ddG (kcal/mol)'].round(4)\n",
        "\n",
        "if len(PREFIX) < 1:\n",
        "  PREFIX = pdb_file.split('.')[0]\n",
        "else:\n",
        "  PREFIX = os.path.join('/content/', PREFIX)\n",
        "\n",
        "full_fname = PREFIX + '.csv'\n",
        "\n",
        "if Model == 'Single':\n",
        "  df['Wildtype AA'] = df['Mutation'].str[0]\n",
        "  df['Mutant AA'] = df['Mutation'].str[-1]\n",
        "  df['Position'] = df['Mutation'].str[2:-1]\n",
        "  df['Chain'] = df['Mutation'].str[1]\n",
        "\n",
        "else:\n",
        "  df[['Mutation 1', 'Mutation 2']] = df['Mutation'].str.split(':', n=2, expand=True)\n",
        "  df['Wildtype AA 1'], df['Wildtype AA 2'] = df['Mutation 1'].str[0], df['Mutation 2'].str[0]\n",
        "  df['Mutant AA 1'], df['Mutant AA 2'] = df['Mutation 1'].str[-1], df['Mutation 2'].str[-1]\n",
        "  df['Position 1'], df['Position 2'] = df['Mutation 1'].str[2:-1], df['Mutation 2'].str[2:-1]\n",
        "  df['Chain 1'], df['Chain 2'] = df['Mutation 1'].str[1], df['Mutation 2'].str[1]\n",
        "\n",
        "df.to_csv(full_fname, index=True)\n",
        "files.download(full_fname)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OX0cjtdNPJoA",
        "outputId": "c8f6821e-0984-4b75-8d08-e4deffa9cde5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fa9839a2-ae1b-4693-8226-9073bc839fd5\", \"test.csv\", 603)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZRyx8WU0cuMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# APPENDIX\n",
        "\n",
        "## License\n",
        "\n",
        "The source code for ThermoMPNN-D, including license information, can be found [here](https://github.com/Kuhlman-Lab/ThermoMPNN-D)\n",
        "\n",
        "## Citation Information\n",
        "\n",
        "If you use ThermoMPNN-D in your research, please cite the following paper(s):\n",
        "\n",
        "### Epistatic or Additive model:\n",
        "Dieckhaus, H., Kuhlman, B., *Protein stability models fail to capture epistatic interactions of double point mutations*. **2024**, bioRxiv, doi: https://doi.org/10.1101/2024.08.20.608844.\n",
        "\n",
        "### Single mutant model:\n",
        "Dieckhaus, H., Brocidiacono, M., Randolph, N., Kuhlman, B. *Transfer learning to leverage larger datasets for improved prediction of protein stability changes.* Proc Natl Acad Sci **2024**, 121(6), e2314853121, doi: https://doi.org/10.1073/pnas.2314853121.\n",
        "\n",
        "## Contact Information\n",
        "\n",
        "# Please contact Henry Dieckhaus at dieckhau@unc.edu to report any bugs or issues with this notebook. You may also submit issues on the ThermoMPNN-D GitHub page [here](https://github.com/Kuhlman-Lab/ThermoMPNN-D/issues).\n"
      ],
      "metadata": {
        "id": "jaIXOllfc2Ok"
      }
    }
  ]
}